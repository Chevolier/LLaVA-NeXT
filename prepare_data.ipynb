{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"data/hualai_sft_data/\"\n",
    "video_dir = \"data/hualai_sft_data/video\"\n",
    "input_file = os.path.join(data_dir, 'output_0314.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>delivery_service</th>\n",
       "      <th>description</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Violent express delivery</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>A delivery driver drops boxes, falls, destroys...</td>\n",
       "      <td>anonymized-1.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Encounter with wildlife</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>A person is delivering a package when a deer s...</td>\n",
       "      <td>anonymized-2.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal express delivery</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>A delivery driver wearing an Amazon uniform de...</td>\n",
       "      <td>anonymized-3.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal express delivery</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The courier, wearing a black t-shirt with desi...</td>\n",
       "      <td>anonymized-4.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal express delivery</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>A person in a red jacket drops off a paper bag...</td>\n",
       "      <td>anonymized-5.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   scenario delivery_service  \\\n",
       "0  Violent express delivery          Unknown   \n",
       "1   Encounter with wildlife          Unknown   \n",
       "2   Normal express delivery           Amazon   \n",
       "3   Normal express delivery          Unknown   \n",
       "4   Normal express delivery          Unknown   \n",
       "\n",
       "                                         description          video_id  \n",
       "0  A delivery driver drops boxes, falls, destroys...  anonymized-1.mp4  \n",
       "1  A person is delivering a package when a deer s...  anonymized-2.mp4  \n",
       "2  A delivery driver wearing an Amazon uniform de...  anonymized-3.mp4  \n",
       "3  The courier, wearing a black t-shirt with desi...  anonymized-4.mp4  \n",
       "4  A person in a red jacket drops off a paper bag...  anonymized-5.mp4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data_list = []\n",
    "for k, v in data.items():\n",
    "    data_list.append(v)\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 101\n",
      "Training samples: 80\n",
      "Test samples: 21\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "data_path = \"data/hualai_sft_data/output_0314.json\"\n",
    "\n",
    "# Load data\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Get all keys\n",
    "keys = list(data.keys())\n",
    "\n",
    "# Randomly shuffle keys\n",
    "random.shuffle(keys)\n",
    "\n",
    "# Calculate split point\n",
    "split_point = int(len(keys) * 0.8)\n",
    "\n",
    "# Split keys into train and test sets\n",
    "train_keys = keys[:split_point]\n",
    "test_keys = keys[split_point:]\n",
    "\n",
    "# Create train and test dictionaries\n",
    "train_data = {k: data[k] for k in train_keys}\n",
    "test_data = {k: data[k] for k in test_keys}\n",
    "\n",
    "# Save train data\n",
    "with open('data/hualai_sft_data/train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save test data\n",
    "with open('data/hualai_sft_data/test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Total samples: {len(data)}\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 21 videos into 21 conversation entries\n",
      "\n",
      "Sample of converted data:\n",
      "{\n",
      "  \"id\": \"anonymized-79\",\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"from\": \"human\",\n",
      "      \"value\": \"<image>\\nThis is the surveillance camera footage from home delivery scenarios. I need you to analyze the content carefully and provide a structured analysis in the following format:\\n\\nscenario: identify the main events in the video, select the most relevant label in [Violent express delivery, Normal express delivery, Express package theft, Encounter with wildlife, Accidental dropping of delivery items, Other abnormal behaviors]\\ndelivery service: identify the delivery company if visible, e.g., FedEx, UPS, Amazon, \\u7f8e\\u56e2\\u5916\\u5356, SAGAWA, DHL, or mark as \\u201cUnknown\\u201d if unclear\\ndescription: provide a brief, one-sentence description of what happens in the video, including key actions and participants ** in English **\\n\\nReturn your analysis in strict JSON format as follows:\\n{{\\n    \\\"scenario\\\": \\\"main event or situation labels\\\",\\n    \\\"delivery_service\\\": \\\"company name or Unknown\\\",\\n    \\\"description\\\": \\\"brief one-sentence description in English\\\",\\n}}\\nPlease ensure the output is valid JSON with these exact keys.\"\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"gpt\",\n",
      "      \"value\": \"{\\\"scenario\\\": \\\"Violent express delivery\\\", \\\"delivery_service\\\": \\\"United States Postal Service\\\", \\\"description\\\": \\\"A USPS mail carrier delivers mail to a residential address.\\\"}\"\n",
      "    }\n",
      "  ],\n",
      "  \"data_source\": \"delivery_dataset\",\n",
      "  \"video\": \"video/anonymized-79.mp4\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"anonymized-66\",\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"from\": \"human\",\n",
      "      \"value\": \"<image>\\nThis is the surveillance camera footage from home delivery scenarios. I need you to analyze the content carefully and provide a structured analysis in the following format:\\n\\nscenario: identify the main events in the video, select the most relevant label in [Violent express delivery, Normal express delivery, Express package theft, Encounter with wildlife, Accidental dropping of delivery items, Other abnormal behaviors]\\ndelivery service: identify the delivery company if visible, e.g., FedEx, UPS, Amazon, \\u7f8e\\u56e2\\u5916\\u5356, SAGAWA, DHL, or mark as \\u201cUnknown\\u201d if unclear\\ndescription: provide a brief, one-sentence description of what happens in the video, including key actions and participants ** in English **\\n\\nReturn your analysis in strict JSON format as follows:\\n{{\\n    \\\"scenario\\\": \\\"main event or situation labels\\\",\\n    \\\"delivery_service\\\": \\\"company name or Unknown\\\",\\n    \\\"description\\\": \\\"brief one-sentence description in English\\\",\\n}}\\nPlease ensure the output is valid JSON with these exact keys.\"\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"gpt\",\n",
      "      \"value\": \"{\\\"scenario\\\": \\\"Violent express delivery\\\", \\\"delivery_service\\\": \\\"Unknown\\\", \\\"description\\\": \\\"A person, presumably a delivery worker, is carrying bags near a building. The person then drops the bags causing the contents to spill on the ground.\\\"}\"\n",
      "    }\n",
      "  ],\n",
      "  \"data_source\": \"delivery_dataset\",\n",
      "  \"video\": \"video/anonymized-66.mp4\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def convert_json_format(input_file, output_file, data_source=\"delivery_dataset\"):\n",
    "    # Read the input JSON file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        input_data = json.load(f)\n",
    "    \n",
    "    # Initialize the output list\n",
    "    output_data = []\n",
    "\n",
    "    prompt = \"\"\"\\\n",
    "This is the surveillance camera footage from home delivery scenarios. I need you to analyze the content carefully and provide a structured analysis in the following format:\n",
    "\n",
    "scenario: identify the main events in the video, select the most relevant label in [Violent express delivery, Normal express delivery, Express package theft, Encounter with wildlife, Accidental dropping of delivery items, Other abnormal behaviors]\n",
    "delivery service: identify the delivery company if visible, e.g., FedEx, UPS, Amazon, 美团外卖, SAGAWA, DHL, or mark as “Unknown” if unclear\n",
    "description: provide a brief, one-sentence description of what happens in the video, including key actions and participants ** in English **\n",
    "\n",
    "Return your analysis in strict JSON format as follows:\n",
    "{{\n",
    "    \"scenario\": \"main event or situation labels\",\n",
    "    \"delivery_service\": \"company name or Unknown\",\n",
    "    \"description\": \"brief one-sentence description in English\",\n",
    "}}\n",
    "Please ensure the output is valid JSON with these exact keys.\\\n",
    "\"\"\"\n",
    "    \n",
    "    # Process each video entry\n",
    "    for idx, (video_id, video_data) in enumerate(input_data.items(), 1):\n",
    "        # Create conversation for scenario question\n",
    "        answer = f\"\"\"\\\n",
    "{{\"scenario\": \"{video_data[\"scenario\"]}\", \\\n",
    "\"delivery_service\": \"{video_data[\"delivery_service\"]}\", \\\n",
    "\"description\": \"{video_data[\"description\"]}\"\\\n",
    "}}\\\n",
    "\"\"\"\n",
    "        entry = {\n",
    "            \"id\": f\"{os.path.splitext(video_id)[0]}\",\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{prompt}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer\n",
    "                }\n",
    "            ],\n",
    "            \"data_source\": data_source,\n",
    "            \"video\": f\"video/{video_id}\"\n",
    "        }\n",
    "        output_data.append(entry)\n",
    "        \n",
    "    # Write the output JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Converted {len(input_data)} videos into {len(output_data)} conversation entries\")\n",
    "    return output_data\n",
    "\n",
    "data_dir = \"data/hualai_sft_data/\"\n",
    "input_file = os.path.join(data_dir, 'train.json')\n",
    "output_file = os.path.join(data_dir, 'train_formatted.json')\n",
    "\n",
    "converted_data = convert_json_format(input_file, output_file)\n",
    "\n",
    "# Print first few entries to verify format\n",
    "print(\"\\nSample of converted data:\")\n",
    "for entry in converted_data[:2]:\n",
    "    print(json.dumps(entry, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
